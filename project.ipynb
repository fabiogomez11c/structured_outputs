{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import instructor\n",
    "\n",
    "from openai import AsyncOpenAI\n",
    "from helpers import dicts_to_df\n",
    "from datetime import date\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class DateRange(BaseModel):\n",
    "    chain_of_thought: str = Field(\n",
    "        description=\"Think step by step to plan what is the best time range to search in\"\n",
    "    )\n",
    "    start: date\n",
    "    end: date\n",
    "\n",
    "\n",
    "class Query(BaseModel):\n",
    "    rewritten_query: str = Field(\n",
    "        description=\"Rewrite the query to make it more specific\"\n",
    "    )\n",
    "    published_daterange: DateRange = Field(\n",
    "        description=\"Effective date range to search in\"\n",
    "    )\n",
    "\n",
    "    def report(self):\n",
    "        dct = self.model_dump()\n",
    "        dct[\"usage\"] = self._raw_response.usage.model_dump()\n",
    "        return dct\n",
    "\n",
    "\n",
    "\n",
    "# We'll use a different client for async calls\n",
    "# To highlight the difference and how we can use both\n",
    "aclient = instructor.patch(AsyncOpenAI())\n",
    "\n",
    "\n",
    "async def expand_query(\n",
    "    q, *, model: str = \"gpt-3.5-turbo\", temp: float = 0\n",
    ") -> Query:\n",
    "    return await aclient.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=temp,\n",
    "        response_model=Query,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"You're a query understanding system for the Metafor Systems search engine. Today is {date.today()}. Here are some tips: ...\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": f\"query: {q}\"},\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/fh/code/structured_outputs/wandb/run-20240327_164248-wwlgmnv2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fabiogomez11c/query/runs/wwlgmnv2/workspace' target=\"_blank\">wobbly-rain-5</a></strong> to <a href='https://wandb.ai/fabiogomez11c/query' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fabiogomez11c/query' target=\"_blank\">https://wandb.ai/fabiogomez11c/query</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fabiogomez11c/query/runs/wwlgmnv2/workspace' target=\"_blank\">https://wandb.ai/fabiogomez11c/query/runs/wwlgmnv2/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 6.7%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>average duration (s)</td><td>▁</td></tr><tr><td>duration (s)</td><td>▁</td></tr><tr><td>n_queries</td><td>▁</td></tr><tr><td>usage_completion_tokens</td><td>▁</td></tr><tr><td>usage_prompt_tokens</td><td>▁</td></tr><tr><td>usage_total_tokens</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>average duration (s)</td><td>0.59857</td></tr><tr><td>duration (s)</td><td>2.39428</td></tr><tr><td>n_queries</td><td>4</td></tr><tr><td>usage_completion_tokens</td><td>200</td></tr><tr><td>usage_prompt_tokens</td><td>780</td></tr><tr><td>usage_total_tokens</td><td>980</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wobbly-rain-5</strong> at: <a href='https://wandb.ai/fabiogomez11c/query/runs/wwlgmnv2/workspace' target=\"_blank\">https://wandb.ai/fabiogomez11c/query/runs/wwlgmnv2/workspace</a><br/>Synced 5 W&B file(s), 2 media file(s), 5 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240327_164248-wwlgmnv2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "import pandas as pd\n",
    "import wandb\n",
    "\n",
    "model = \"gpt-3.5-turbo\"\n",
    "temp = 1\n",
    "\n",
    "run = wandb.init(\n",
    "    project=\"query\",\n",
    "    config={\"model\": model, \"temp\": temp},\n",
    ")\n",
    "\n",
    "test_queries = [\n",
    "    \"latest developments in artificial intelligence last 3 weeks\",\n",
    "    \"renewable energy trends past month\",\n",
    "    \"quantum computing advancements last 2 months\",\n",
    "    \"biotechnology updates last 10 days\",\n",
    "]\n",
    "start = time.perf_counter()\n",
    "queries = await asyncio.gather(\n",
    "    *[expand_query(q, model=model, temp=temp) for q in test_queries]\n",
    ")\n",
    "duration = time.perf_counter() - start\n",
    "\n",
    "with open(\"schema.json\", \"w+\") as f:\n",
    "    schema = Query.model_json_schema()\n",
    "    json.dump(schema, f, indent=2)\n",
    "\n",
    "with open(\"results.jsonlines\", \"w+\") as f:\n",
    "    for query in queries:\n",
    "        f.write(query.model_dump_json() + \"\\n\")\n",
    "\n",
    "df = dicts_to_df([q.report() for q in queries])\n",
    "df[\"input\"] = test_queries\n",
    "df.to_csv(\"results.csv\")\n",
    "\n",
    "\n",
    "run.log({\"schema\": wandb.Table(dataframe=pd.DataFrame([{\"schema\": schema}]))})\n",
    "\n",
    "run.log(\n",
    "    {\n",
    "        \"usage_total_tokens\": df[\"usage_total_tokens\"].sum(),\n",
    "        \"usage_completion_tokens\": df[\"usage_completion_tokens\"].sum(),\n",
    "        \"usage_prompt_tokens\": df[\"usage_prompt_tokens\"].sum(),\n",
    "        \"duration (s)\": duration,\n",
    "        \"average duration (s)\": duration / len(queries),\n",
    "        \"n_queries\": len(queries),\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "run.log(\n",
    "    {\n",
    "        \"results\": wandb.Table(dataframe=df),\n",
    "    }\n",
    ")\n",
    "\n",
    "files = wandb.Artifact(\"data\", type=\"dataset\")\n",
    "\n",
    "files.add_file(\"schema.json\")\n",
    "files.add_file(\"results.jsonlines\")\n",
    "files.add_file(\"results.csv\")\n",
    "\n",
    "\n",
    "run.log_artifact(files)\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soutputs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
